{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60966c89-de41-401e-89fa-bc821fae3b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.path.abspath(os.path.dirname(os.path.realpath(\"__file__\")))\n",
    "crepe_path = os.path.join(current_dir, '..', 'crepe')\n",
    "sys.path.append(crepe_path)\n",
    "\n",
    "import crepe\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382fc8e7",
   "metadata": {},
   "source": [
    "# Using Crepe to Extract Frequency audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994379d-d717-46ec-bd5a-2dce4bcaf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_detection(input_audio_path):\n",
    "    # Load the pre-trained crepe model\n",
    "    model_capacity = 'small'\n",
    "\n",
    "    # Load the guitar audio file\n",
    "    y, sr = librosa.load(input_audio_path)\n",
    "\n",
    "    # Pitch detection\n",
    "    time, frequency, confidence, activation = crepe.predict(y, sr, viterbi=True, model_capacity=model_capacity)\n",
    "\n",
    "    # Plot the pitch detection results\n",
    "    #plt.figure(figsize=(10, 6))\n",
    "    #plt.subplot(3, 1, 1)\n",
    "    #plt.plot(time, frequency, 'r')\n",
    "    # plt.title('Estimated Pitch (CREPE)')\n",
    "    # plt.xlabel('Time (s)')\n",
    "    # plt.ylabel('Frequency (Hz)')\n",
    "\n",
    "    # plt.subplot(3, 1, 2)\n",
    "    # plt.plot(time, confidence, 'g')\n",
    "    # plt.title('Pitch Confidence')\n",
    "    # plt.xlabel('Time (s)')\n",
    "    # plt.ylabel('Confidence')\n",
    "\n",
    "    # plt.subplot(3, 1, 3)\n",
    "    # plt.plot(time, activation, 'b')\n",
    "    # plt.title('Activation')\n",
    "    # plt.xlabel('Time (s)')\n",
    "    # plt.ylabel('Activation')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    return np.array(time), np.array(frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_input_path = \"input-audios/guitar.wav\"\n",
    "input_path = os.path.abspath(os.path.join(os.getcwd(), relative_input_path))\n",
    "time_values, frequency_values = pitch_detection(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, sr = librosa.load(input_path)\n",
    "\n",
    "# # Compute the Short-Time Fourier Transform (STFT)\n",
    "# hop_length = 512  #adustable\n",
    "# n_fft = 2048  # adustable\n",
    "# stft = librosa.core.stft(y, hop_length=hop_length, n_fft=n_fft)\n",
    "\n",
    "# # Convert amplitude to decibels\n",
    "# stft_db = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
    "\n",
    "# # Extract time and frequency\n",
    "# time_values = librosa.times_like(stft)\n",
    "# frequency_values = librosa.fft_frequencies(sr=sr, n_fft=n_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6fa7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "\n",
    "def interpolate_linearly(wave_table, index):\n",
    "    truncated_index = int(np.floor(index))\n",
    "    next_index = (truncated_index + 1) % wave_table.shape[0]\n",
    "    next_index_weight = index - truncated_index\n",
    "    truncated_index_weight = 1 - next_index_weight\n",
    "    return truncated_index_weight * wave_table[truncated_index] + next_index_weight * wave_table[next_index]\n",
    "\n",
    "def fade_in_out(signal, fade_length=1000):\n",
    "    if fade_length > len(signal):\n",
    "        fade_length = len(signal)\n",
    "\n",
    "    fade_in = (1 - np.cos(np.linspace(0, np.pi, fade_length))) * 0.5\n",
    "    fade_out = np.flip(fade_in)\n",
    "\n",
    "    signal[:fade_length] = np.multiply(fade_in, signal[:fade_length])\n",
    "\n",
    "    if len(signal) > fade_length:\n",
    "        signal[-fade_length:] = np.multiply(fade_out, signal[-fade_length:])\n",
    "\n",
    "    return signal\n",
    "\n",
    "def generate_wave_table(wavetable_length=64):\n",
    "    wave_table = np.zeros((wavetable_length,))\n",
    "    for n in range(wavetable_length):\n",
    "        wave_table[n] = np.sin(2 * np.pi * n / wavetable_length)\n",
    "    return wave_table\n",
    "\n",
    "def wavetable_synthesis(time, frequency, sample_rate=44100, wavetable_length=64, fade_length=1000):\n",
    "    output = np.zeros((0,))\n",
    "    wave_table = generate_wave_table(wavetable_length)\n",
    "\n",
    "    for t, f in zip(time, frequency):\n",
    "        current_signal = np.zeros((int(t * sample_rate),))\n",
    "        index = 0\n",
    "        index_increment = f * wavetable_length / sample_rate\n",
    "\n",
    "        for n in range(current_signal.shape[0]):\n",
    "            current_signal[n] = interpolate_linearly(wave_table, index)\n",
    "            index += index_increment\n",
    "            index %= wavetable_length\n",
    "\n",
    "        gain = -20\n",
    "        amplitude = 10 ** (gain / 20)\n",
    "        current_signal *= amplitude\n",
    "\n",
    "        current_signal = fade_in_out(current_signal, fade_length)\n",
    "\n",
    "        # Concatenate the current signal to the output\n",
    "        output = np.concatenate((output, current_signal))\n",
    "\n",
    "    return output\n",
    "\n",
    "def main():\n",
    "    sample_rate = 44100\n",
    "\n",
    "    time = time_values\n",
    "    frequency = frequency_values \n",
    "    synthesized_output = wavetable_synthesis(time, frequency, sample_rate)\n",
    "\n",
    "    relative_output_path = \"output-audios/synthesised.wav\"\n",
    "    output_path = os.path.abspath(os.path.join(os.getcwd(), relative_output_path))\n",
    "\n",
    "\n",
    "    # Save the final synthesized output\n",
    "    wav.write(output_path, sample_rate, synthesized_output.astype(np.float32))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31bcfbd-d580-45a0-9c34-967f0a805009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import sounddevice as sd\n",
    "\n",
    "# def generate_piano_sound(time_data, frequency_data, sample_rate=44100):\n",
    "#     time = np.arange(0, max(time_data), 1/sample_rate)\n",
    "\n",
    "#     # Interpolate frequencies for the given time\n",
    "#     frequency = np.interp(time, time_data, frequency_data)\n",
    "\n",
    "#     # Generate piano sound using sine waves\n",
    "#     piano_sound = np.zeros_like(time)\n",
    "#     for freq in frequency:\n",
    "#         piano_sound += np.sin(2 * np.pi * freq * time)\n",
    "\n",
    "#     # Normalize the sound to prevent clipping\n",
    "#     piano_sound /= np.max(np.abs(piano_sound))\n",
    "\n",
    "#     return piano_sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c03e7-02b8-455f-8d0a-e0cce967a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import wavfile\n",
    "\n",
    "# def create_piano_from_guitar(input_guitar_path, output_audio_path):\n",
    "#     # Pitch detection\n",
    "#     time_data, estimated_pitch = pitch_detection(input_guitar_path)\n",
    "\n",
    "#     # Generate piano sound based on time and frequency data\n",
    "#     piano_sound = generate_piano_sound(time_data, estimated_pitch)\n",
    "\n",
    "#     print(\"piano_sound\")\n",
    "\n",
    "#     sd.play(piano_sound, samplerate=44100)\n",
    "#     sd.wait()\n",
    "\n",
    "\n",
    "#     # # Save the generated piano sound to a file (optional\n",
    "#     # wavfile.write(output_audio_path, 44100, np.int16(piano_sound * 32767))\n",
    "\n",
    "# # Example usage\n",
    "# input_guitar_path = \"/input-audios/guitar.wav\"\n",
    "# output_audio_path = \"/output_audios/generated.wav\"\n",
    "\n",
    "# create_piano_from_guitar(input_guitar_path, output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5ef07-131e-4a25-8af9-21ed0fcea5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_wave_table(frequency, duration=1.0, sample_rate=44100):\n",
    "#     time = np.arange(0, duration, 1/sample_rate)\n",
    "\n",
    "#     # Generate sine waveforms for each frequency\n",
    "#     wave_table = np.sin(2 * np.pi * frequency * time[:, np.newaxis])\n",
    "\n",
    "#     return wave_table\n",
    "\n",
    "# def wave_table_synthesis(input_audio_path):\n",
    "#     # Pitch detection using Crepe\n",
    "#     time, frequency = pitch_detection(input_audio_path)\n",
    "\n",
    "#     # Generate wave table\n",
    "#     wave_table = generate_wave_table(frequency)\n",
    "\n",
    "#     # Synthesize audio using wave table\n",
    "#     synthesized_audio = np.sum(wave_table, axis=1)\n",
    "\n",
    "#     # Play the synthesized audio using Sounddevice\n",
    "#     sd.play(synthesized_audio, samplerate=44100)\n",
    "#     sd.wait()\n",
    "# input_audio_path = \"/input-audios/guitar.wav\"\n",
    "# wave_table_synthesis(input_audio_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
